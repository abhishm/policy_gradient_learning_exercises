{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing Gridworld using Actor/Critic\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "This tutorial builds off of [Outlace's excelent blog entry on Q-Learning](http://outlace.com/Reinforcement-Learning-Part-3/) and this is the [starting point](https://www2.informatik.uni-hamburg.de/~weber/code/ActorCritic.py) for my Actor Critic implementation.\n",
    "\n",
    "I got interested in Actor-Critic reinforcement learning after skimming DeepMind's follow-up to their original Atari paper. The new paper [Asynchronous Methods for Deep Reinforcement Learning](http://arxiv.org/abs/1602.01783) uses an Actor/Critic learning implementation to surpass the performance of their original Deep Q-Network. I couldn't find a good straightforward implementation/example of it.\n",
    "\n",
    "For a slightly more in-depth explination check out [Actor-Critic Methods](https://webdocs.cs.ualberta.ca/~sutton/book/ebook/node66.html) from the book 'Reinforcement Learning: An Introduction' by Sutton and Barto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Gridworld\n",
    "\n",
    "This is the gridworld implementation from [the original Q-learning tutorial](http://outlace.com/Reinforcement-Learning-Part-3/) which we will use as the environment for our Actor/Critic learner. One small tweak I made is to end the episode if the Agent has made more than 40 moves but still hasn't made it to a terminal state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# This is added - implicitly limit move count.\n",
    "MAX_MOVES=40\n",
    "move_counter = 0\n",
    "\n",
    "def randPair(s,e):\n",
    "    return np.random.randint(s,e), np.random.randint(s,e)\n",
    "\n",
    "#finds an array in the \"depth\" dimension of the grid\n",
    "def findLoc(state, obj):\n",
    "    for i in range(0,4):\n",
    "        for j in range(0,4):\n",
    "            if (state[i,j] == obj).all():\n",
    "                return i,j\n",
    "\n",
    "#Initialize stationary grid, all items are placed deterministically\n",
    "def initGrid():\n",
    "    global move_counter\n",
    "    move_counter = 0\n",
    "    state = np.zeros((4,4,4))\n",
    "    #place player\n",
    "    state[0,1] = np.array([0,0,0,1])\n",
    "    #place wall\n",
    "    state[2,2] = np.array([0,0,1,0])\n",
    "    #place pit\n",
    "    state[1,1] = np.array([0,1,0,0])\n",
    "    #place goal\n",
    "    state[3,3] = np.array([1,0,0,0])\n",
    "    \n",
    "    return state\n",
    "\n",
    "#Initialize player in random location, but keep wall, goal and pit stationary\n",
    "def initGridPlayer():\n",
    "    global move_counter\n",
    "    move_counter = 0\n",
    "    state = np.zeros((4,4,4))\n",
    "    #place player\n",
    "    state[randPair(0,4)] = np.array([0,0,0,1])\n",
    "    #place wall\n",
    "    state[2,2] = np.array([0,0,1,0])\n",
    "    #place pit\n",
    "    state[1,1] = np.array([0,1,0,0])\n",
    "    #place goal\n",
    "    state[1,2] = np.array([1,0,0,0])\n",
    "    \n",
    "    a = findLoc(state, np.array([0,0,0,1])) #find grid position of player (agent)\n",
    "    w = findLoc(state, np.array([0,0,1,0])) #find wall\n",
    "    g = findLoc(state, np.array([1,0,0,0])) #find goal\n",
    "    p = findLoc(state, np.array([0,1,0,0])) #find pit\n",
    "    if (not a or not w or not g or not p):\n",
    "        #print('Invalid grid. Rebuilding..')\n",
    "        return initGridPlayer()\n",
    "    \n",
    "    return state\n",
    "\n",
    "#Initialize grid so that goal, pit, wall, player are all randomly placed\n",
    "def initGridRand():\n",
    "    global move_counter\n",
    "    move_counter = 0\n",
    "    state = np.zeros((4,4,4))\n",
    "    #place player\n",
    "    state[randPair(0,4)] = np.array([0,0,0,1])\n",
    "    #place wall\n",
    "    state[randPair(0,4)] = np.array([0,0,1,0])\n",
    "    #place pit\n",
    "    state[randPair(0,4)] = np.array([0,1,0,0])\n",
    "    #place goal\n",
    "    state[randPair(0,4)] = np.array([1,0,0,0])\n",
    "    \n",
    "    a = findLoc(state, np.array([0,0,0,1]))\n",
    "    w = findLoc(state, np.array([0,0,1,0]))\n",
    "    g = findLoc(state, np.array([1,0,0,0]))\n",
    "    p = findLoc(state, np.array([0,1,0,0]))\n",
    "    #If any of the \"objects\" are superimposed, just call the function again to re-place\n",
    "    if (not a or not w or not g or not p):\n",
    "        #print('Invalid grid. Rebuilding..')\n",
    "        return initGridRand()\n",
    "    \n",
    "    return state\n",
    "\n",
    "def makeMove(state, action):\n",
    "    #need to locate player in grid\n",
    "    #need to determine what object (if any) is in the new grid spot the player is moving to\n",
    "    player_loc = findLoc(state, np.array([0,0,0,1]))\n",
    "    wall = findLoc(state, np.array([0,0,1,0]))\n",
    "    goal = findLoc(state, np.array([1,0,0,0]))\n",
    "    pit = findLoc(state, np.array([0,1,0,0]))\n",
    "    state = np.zeros((4,4,4))\n",
    "    \n",
    "    #up (row - 1)\n",
    "    if action==0:\n",
    "        new_loc = (player_loc[0] - 1, player_loc[1])\n",
    "        if (new_loc != wall):\n",
    "            if ((np.array(new_loc) <= (3,3)).all() and (np.array(new_loc) >= (0,0)).all()):\n",
    "                state[new_loc][3] = 1\n",
    "    #down (row + 1)\n",
    "    elif action==1:\n",
    "        new_loc = (player_loc[0] + 1, player_loc[1])\n",
    "        if (new_loc != wall):\n",
    "            if ((np.array(new_loc) <= (3,3)).all() and (np.array(new_loc) >= (0,0)).all()):\n",
    "                state[new_loc][3] = 1\n",
    "    #left (column - 1)\n",
    "    elif action==2:\n",
    "        new_loc = (player_loc[0], player_loc[1] - 1)\n",
    "        if (new_loc != wall):\n",
    "            if ((np.array(new_loc) <= (3,3)).all() and (np.array(new_loc) >= (0,0)).all()):\n",
    "                state[new_loc][3] = 1\n",
    "    #right (column + 1)\n",
    "    elif action==3:\n",
    "        new_loc = (player_loc[0], player_loc[1] + 1)\n",
    "        if (new_loc != wall):\n",
    "            if ((np.array(new_loc) <= (3,3)).all() and (np.array(new_loc) >= (0,0)).all()):\n",
    "                state[new_loc][3] = 1\n",
    "                \n",
    "    new_player_loc = findLoc(state, np.array([0,0,0,1]))\n",
    "    if (not new_player_loc):\n",
    "        state[player_loc] = np.array([0,0,0,1])\n",
    "    #re-place pit\n",
    "    state[pit][1] = 1\n",
    "    #re-place wall\n",
    "    state[wall][2] = 1\n",
    "    #re-place goal\n",
    "    state[goal][0] = 1\n",
    "    global move_counter\n",
    "    move_counter += 1\n",
    "    \n",
    "    return state\n",
    "\n",
    "def getLoc(state, level):\n",
    "    for i in range(0,4):\n",
    "        for j in range(0,4):\n",
    "            if (state[i,j][level] == 1):\n",
    "                return i,j\n",
    "\n",
    "def getReward(state):\n",
    "    player_loc = getLoc(state, 3)\n",
    "    pit = getLoc(state, 1)\n",
    "    goal = getLoc(state, 0)\n",
    "    if (player_loc == pit):\n",
    "        return -10\n",
    "    elif (player_loc == goal):\n",
    "        return 10\n",
    "    elif (move_counter > MAX_MOVES):\n",
    "        return -9\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def dispGrid(state):\n",
    "    grid = np.zeros((4,4), dtype='<U2')\n",
    "    player_loc = findLoc(state, np.array([0,0,0,1]))\n",
    "    wall = findLoc(state, np.array([0,0,1,0]))\n",
    "    goal = findLoc(state, np.array([1,0,0,0]))\n",
    "    pit = findLoc(state, np.array([0,1,0,0]))\n",
    "    for i in range(0,4):\n",
    "        for j in range(0,4):\n",
    "            grid[i,j] = ' '\n",
    "            \n",
    "    if player_loc:\n",
    "        grid[player_loc] = 'P' #player\n",
    "    if wall:\n",
    "        grid[wall] = 'W' #wall\n",
    "    if goal:\n",
    "        grid[goal] = '+' #goal\n",
    "    if pit:\n",
    "        grid[pit] = '-' #pit\n",
    "    \n",
    "    return grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make sure our original implementation is working before we continue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[u' ', u'P', u' ', u' '],\n",
       "       [u' ', u'-', u' ', u' '],\n",
       "       [u' ', u' ', u'W', u' '],\n",
       "       [u' ', u' ', u' ', u'+']], \n",
       "      dtype='<U2')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = initGrid()\n",
    "dispGrid(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And move our player into the winning position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[u' ', u' ', u' ', u' '],\n",
       "       [u' ', u'-', u' ', u' '],\n",
       "       [u' ', u' ', u'W', u' '],\n",
       "       [u' ', u' ', u' ', u' ']], \n",
       "      dtype='<U2')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEFT=2\n",
    "RIGHT=3\n",
    "UP=0\n",
    "DOWN=1\n",
    "A2S=['up','down','left','right']\n",
    "state = initGrid()\n",
    "state = makeMove(state, RIGHT)\n",
    "state = makeMove(state, RIGHT)\n",
    "state = makeMove(state, DOWN)\n",
    "state = makeMove(state, DOWN)\n",
    "state = makeMove(state, DOWN)\n",
    "print('Reward: %s' % (getReward(state),))\n",
    "dispGrid(state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Actor\n",
    "\n",
    "In Actor/Critic there are two networks. The 'policy' network (the Actor) and the 'value' network (the Critic). You will recognize the policy network as being essentially the same as the network from the Q-Learning example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actor_model = Sequential()\n",
    "actor_model.add(Dense(164, init='lecun_uniform', input_shape=(64,)))\n",
    "actor_model.add(Activation('relu'))\n",
    "\n",
    "actor_model.add(Dense(150, init='lecun_uniform'))\n",
    "actor_model.add(Activation('relu'))\n",
    "\n",
    "actor_model.add(Dense(4, init='lecun_uniform'))\n",
    "actor_model.add(Activation('linear'))\n",
    "\n",
    "rms = RMSprop()\n",
    "actor_model.compile(loss='mse', optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up the Critic network. This network looks very similar to the Actor model, but only outputs a single value - it outputs a value (the score) for the input state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "critic_model = Sequential()\n",
    "\n",
    "critic_model.add(Dense(256, init='lecun_uniform', input_shape=(64,)))\n",
    "critic_model.add(Activation('relu'))\n",
    "\n",
    "critic_model.add(Dense(128, init='lecun_uniform'))\n",
    "critic_model.add(Activation('relu'))\n",
    "\n",
    "critic_model.add(Dense(64, init='lecun_uniform'))\n",
    "critic_model.add(Activation('relu'))\n",
    "\n",
    "critic_model.add(Dense(1, init='lecun_uniform', activation='linear' ))\n",
    "\n",
    "rms = RMSprop()\n",
    "critic_model.compile(loss='mse', optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'test' stays essentially the same. It is important to note, that when testing, we only need the actor/policy network. The critic network is not involved. The Actor has learned the correct policy/moves as it trains on the values supplied by the critic network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testAlgo( initial_state=initGrid() ):\n",
    "    state = initial_state.copy()\n",
    "\n",
    "    print(\"Initial State:\")\n",
    "    print(dispGrid(state))\n",
    "    i = 0\n",
    "    status = 1\n",
    "    #while game still in progress\n",
    "    while(status == 1):\n",
    "        qval = actor_model.predict(state.reshape(1,64), batch_size=1)\n",
    "        action = (np.argmax(qval)) #take action with highest Q-value\n",
    "        print('Move #: %s; Taking action: %s' % (i, A2S[action]))\n",
    "        state = makeMove(state, action)\n",
    "        print(dispGrid(state))\n",
    "        reward = getReward(state)\n",
    "        if reward != -1:\n",
    "            status = 0\n",
    "            print(\"Reward: %s\" % (reward,))\n",
    "        i += 1 #If we're taking more than 10 actions, just stop, we probably can't win this game\n",
    "        if (i > 10):\n",
    "            print(\"Game lost; too many moves.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Trainer\n",
    "\n",
    "The trainer is implemented below. Items of note.\n",
    "* __early stopping__ the trainer implements early-stopping. If the game is winning a given percentage of the time (99% is the default) then the trainer will stop early. No point training any further.\n",
    "* __experience replay__ essentially the same as the example in the Q-learning tutorial. However we replay both the Actor and the Critic's experiences\n",
    "\n",
    "The big main new things here are the split of the Critic network, and state values, from the Actor, and action selection.\n",
    "\n",
    "To train the critic network, we use a simlar process to training value into Q networks. We look at the initial state, make a move, and then look at the new state. For the value network, if we are in a terminal state, that's the value we tell the value network to place on that state. If we are in a non-terminal state, we tell the value network to place a value on the original state which is the reward in the original state, plus the discounted value from the new state. Note that the value network should return the maximum possible value for a given state. If the player's next move could be either jumping into the pit or arriving at the goal, we should set the value as if the best-possible action will be selected.\n",
    "\n",
    "After the critic network has assigned a value to the original and the new state, we adjust the policy. This is simply by looking at our value in our old state, and the value in the new state. If the value improves we encourage that action. If it decreases we discourage the action.\n",
    "\n",
    "When we start training, both the actor and the critic networks are spitting out nonsensical values. Which means initially the actor network is training on values from the critic network which are garbage. However as the critic network improves, those improvements naturally correct and improve the performance of the actor network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import random\n",
    "import time\n",
    "\n",
    "def trainer(game_type='easy',epochs=1000, batchSize=40, \n",
    "            gamma=0.9, epsilon=1, min_epsilon=0.1,\n",
    "            buffer=80,earlystop=0.99):\n",
    "    \n",
    "    status = 1\n",
    "    \n",
    "    # Early-stopping.\n",
    "    earlystop_acc = 0.0\n",
    "    earlystop_decay = 0.9\n",
    "        \n",
    "    # Replay buffers\n",
    "    actor_replay = []\n",
    "    critic_replay = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        if game_type == 'hard':\n",
    "            state = initGridRand()\n",
    "        elif game_type == 'medium':\n",
    "            state = initGridPlayer()\n",
    "        else:\n",
    "            state = initGrid() # easy\n",
    "\n",
    "        status = 1\n",
    "        #while game still in progress\n",
    "        while(status == 1):\n",
    "            # Get original state, original reward, and critic's value for this state.\n",
    "            orig_state = np.copy(state)\n",
    "            orig_reward = getReward(orig_state)\n",
    "            orig_val = critic_model.predict(orig_state.reshape(1,64))\n",
    "\n",
    "            if (random.random() < epsilon): #choose random action\n",
    "                action = np.random.randint(0,4)\n",
    "            else: #choose best action from Q(s,a) values\n",
    "                qval = actor_model.predict( orig_state.reshape(1,64) )\n",
    "                action = (np.argmax(qval))\n",
    "                \n",
    "            #Take action, observe new state S'\n",
    "            new_state = makeMove(state, action)\n",
    "            #Observe reward\n",
    "            new_reward = getReward(new_state)\n",
    "            \n",
    "            # Critic's value for this new state.\n",
    "            new_val = critic_model.predict(new_state.reshape(1,64))\n",
    "            \n",
    "            if new_reward == -1: # Non-terminal state.\n",
    "                target = orig_reward + ( gamma * new_val)\n",
    "            else:\n",
    "                # In terminal states, the environment tells us\n",
    "                # the value directly.\n",
    "                target = orig_reward + ( gamma * new_reward )\n",
    "            \n",
    "            # For our critic, we select the best/highest value.. The\n",
    "            # value for this state is based on if the agent selected\n",
    "            # the best possible moves from this state forward.\n",
    "            # \n",
    "            # BTW, we discount an original value provided by the\n",
    "            # value network, to handle cases where its spitting\n",
    "            # out unreasonably high values.. naturally decaying\n",
    "            # these values to something reasonable.\n",
    "            best_val = max((orig_val*gamma), target)\n",
    "\n",
    "            # Now append this to our critic replay buffer.\n",
    "            critic_replay.append([orig_state,best_val])\n",
    "            # If we are in a terminal state, append a replay for it also.\n",
    "            if new_reward != -1:\n",
    "                critic_replay.append( [new_state, float(new_reward)] )\n",
    "            \n",
    "            # Build the update for the Actor. The actor is updated\n",
    "            # by using the difference of the value the critic\n",
    "            # placed on the old state vs. the value the critic\n",
    "            # places on the new state.. encouraging the actor\n",
    "            # to move into more valuable states.\n",
    "            actor_delta = new_val - orig_val                \n",
    "            actor_replay.append([orig_state, action, actor_delta])\n",
    "                    \n",
    "            # Critic Replays...\n",
    "            while(len(critic_replay) > buffer): # Trim replay buffer\n",
    "                critic_replay.pop(0)\n",
    "            # Start training when we have enough samples.\n",
    "            if(len(critic_replay) >= buffer):\n",
    "                minibatch = random.sample(critic_replay, batchSize)\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                for memory in minibatch:\n",
    "                    m_state, m_value = memory\n",
    "                    y = np.empty([1])\n",
    "                    y[0] = m_value\n",
    "                    X_train.append(m_state.reshape((64,)))\n",
    "                    y_train.append(y.reshape((1,)))\n",
    "                X_train = np.array(X_train)\n",
    "                y_train = np.array(y_train)\n",
    "                critic_model.fit(X_train, y_train, batch_size=batchSize, nb_epoch=1, verbose=0)\n",
    "            \n",
    "            # Actor Replays...\n",
    "            while(len(actor_replay) > buffer):\n",
    "                actor_replay.pop(0)                \n",
    "            if(len(actor_replay) >= buffer):\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                minibatch = random.sample(actor_replay, batchSize)\n",
    "                for memory in minibatch:\n",
    "                    m_orig_state, m_action, m_value = memory\n",
    "                    old_qval = actor_model.predict( m_orig_state.reshape(1,64,) )\n",
    "                    y = np.zeros(( 1, 4 ))\n",
    "                    y[:] = old_qval[:]\n",
    "                    # non-standard - decay actions we aren't selecting on this turn.\n",
    "                    #y[:] = old_qval[:] * gamma\n",
    "                    y[0][m_action] = m_value\n",
    "                    X_train.append(m_orig_state.reshape((64,)))\n",
    "                    y_train.append(y.reshape((4,)))\n",
    "                X_train = np.array(X_train)\n",
    "                y_train = np.array(y_train)\n",
    "                actor_model.fit(X_train, y_train, batch_size=batchSize, nb_epoch=1, verbose=0)\n",
    "\n",
    "            # Finished replays.\n",
    "                \n",
    "            state = new_state\n",
    "            if new_reward != -1:\n",
    "                status = 0\n",
    "                # Count wins/losses for early-stopping.\n",
    "                if new_reward == 10: # Win\n",
    "                    earlystop_result = 1.0\n",
    "                else: # Loss\n",
    "                    earlystop_result = 0.0\n",
    "                new_acc = ( earlystop_acc * earlystop_decay ) + \\\n",
    "                    ((1.0 - earlystop_decay ) * earlystop_result)\n",
    "                earlystop_acc = new_acc\n",
    "\n",
    "        # Finised Epoch\n",
    "        clear_output(wait=True)\n",
    "        print(\"Game #: %s\" % (i,))\n",
    "        print(\"Accumulated win percent: %.2f%%\" % (earlystop_acc*100) )\n",
    "\n",
    "        if epsilon > min_epsilon:\n",
    "            epsilon -= (1/epochs)\n",
    "        # Check if we can early-stop training.\n",
    "        if earlystop_acc > earlystop:\n",
    "            print(\"Early-Stopping Training\")\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game #: 999\n",
      "Accumulated win percent: 11.48%\n"
     ]
    }
   ],
   "source": [
    "trainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For me, the training early-stops after acheving better than a 99% score. Well before 1000 epochs are complete. Lets see how we did by testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State:\n",
      "[[u' ' u'P' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 0; Taking action: right\n",
      "[[u' ' u' ' u'P' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 1; Taking action: down\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u'P' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 2; Taking action: right\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u'P']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 3; Taking action: down\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u'P']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 4; Taking action: down\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u' ']]\n",
      "Reward: 10\n"
     ]
    }
   ],
   "source": [
    "testAlgo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can examine what the value network has learned - and the values it has placed on any given location on the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board State:\n",
      "[[u' ' u'P' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEZCAYAAAB2AoVaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSfYREQ3w/wFGg18hWfH31QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe138a14710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_value(initial_state):\n",
    "    np_w_cri_r = np.zeros((4,4))\n",
    "    # Remove player from initial state.\n",
    "    working_state = initial_state.copy()\n",
    "    p = findLoc(working_state, np.array([0,0,0,1]))\n",
    "    working_state[p[0],p[1]] = np.array([0,0,0,0])\n",
    "    for x in range(0,4):\n",
    "        for y in range(0,4):\n",
    "            my_state = working_state.copy()\n",
    "            # Place the player at a given X/Y location.\n",
    "            my_state[x,y,3] = 1\n",
    "            # And now have the critic model predict the state value\n",
    "            # with the player in that location.\n",
    "            value = critic_model.predict(my_state.reshape(1, 64))\n",
    "            #print(\"x,y: %s, %s - value %f\" % (x, y, value) )\n",
    "            np_w_cri_r[x,y] = value\n",
    "    np_w_cri_r.shape\n",
    "    pylab.pcolor(np_w_cri_r)\n",
    "    pylab.title(\"Value Network\")\n",
    "    pylab.colorbar()\n",
    "    pylab.xlabel(\"X\")\n",
    "    pylab.ylabel(\"Y\")\n",
    "    pylab.gca().invert_yaxis()\n",
    "    pylab.draw()\n",
    "\n",
    "easy_state = initGrid()\n",
    "print(\"Board State:\")\n",
    "print(dispGrid(easy_state))\n",
    "plot_value(easy_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the value network has placed a high value on the winning final position. That value equaling the reward gained when in that position. It also places a very low value on the 'pit' position. Makes sense. Then we can see that the network places ever growing value on positions which move us closer to the winning position. Thus the value network can express to the policy network that a move which moves us closer to the winning position is more valuable. Lets take a look at what the policy network has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board State\n",
      "[[u' ' u'P' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Action Policy\n",
      "[[u'>' u'>' u'v' u'v']\n",
      " [u'v' u'v' u'>' u'v']\n",
      " [u'>' u'v' u'>' u'v']\n",
      " [u'>' u'>' u'>' u'v']]\n"
     ]
    }
   ],
   "source": [
    "A2A=['^','v','<','>']\n",
    "def show_policy(initial_state):\n",
    "    grid = np.zeros((4,4), dtype='<U2')\n",
    "    working_state = initial_state.copy()\n",
    "    p = findLoc(working_state, np.array([0,0,0,1]))\n",
    "    working_state[p[0],p[1]] = np.array([0,0,0,0])\n",
    "    for x in range(0,4):\n",
    "        for y in range(0,4):\n",
    "            #for a in range(0, 4):\n",
    "            my_state = working_state.copy()\n",
    "            my_state[x,y,3] = 1\n",
    "            #\n",
    "            qval = actor_model.predict(my_state.reshape(1, 64))\n",
    "            action = (np.argmax(qval))\n",
    "            grid[x,y] = A2A[action]\n",
    "    return grid\n",
    "\n",
    "easy_state = initGrid()\n",
    "print(\"Board State\")\n",
    "print(dispGrid(easy_state))\n",
    "print(\"Action Policy\")\n",
    "print(show_policy(easy_state))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets just dive into training on the hard variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game #: 4999\n",
      "Accumulated win percent: 22.98%\n"
     ]
    }
   ],
   "source": [
    "trainer(game_type='hard',epochs=5000,earlystop=0.999,min_epsilon=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State:\n",
      "[[u' ' u' ' u' ' u'+']\n",
      " [u' ' u' ' u'W' u'P']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u'-' u' ']]\n",
      "Move #: 0; Taking action: up\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u'-' u' ']]\n",
      "Reward: 10\n"
     ]
    }
   ],
   "source": [
    "hard_state = initGridRand()\n",
    "testAlgo(hard_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a quick look at what our agent learned to solve this grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board State:\n",
      "[[u' ' u' ' u' ' u'+']\n",
      " [u' ' u' ' u'W' u'P']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u'-' u' ']]\n",
      "Policy\n",
      "[[u'>' u'>' u'>' u'v']\n",
      " [u'v' u'>' u'>' u'^']\n",
      " [u'>' u'^' u'<' u'>']\n",
      " [u'v' u'<' u'v' u'^']]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEZCAYAAACKF66QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmY150JuZlZzLuRmZjX3/wG4sexUnA+mPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe12c37e650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Board State:\")\n",
    "print(dispGrid(hard_state))\n",
    "plot_value(hard_state)\n",
    "print(\"Policy\")\n",
    "print(show_policy(hard_state))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent can solve many random configurations of gridworld.. But there's some configurations which give it trouble. It seems to have a hard time with walls. Here's an example problematic grid configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State:\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u' ' u'P' u'-' u' ']\n",
      " [u' ' u'W' u'+' u' ']]\n",
      "Move #: 0; Taking action: left\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u'P' u' ' u'-' u' ']\n",
      " [u' ' u'W' u'+' u' ']]\n",
      "Move #: 1; Taking action: right\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u' ' u'P' u'-' u' ']\n",
      " [u' ' u'W' u'+' u' ']]\n",
      "Move #: 2; Taking action: left\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u'P' u' ' u'-' u' ']\n",
      " [u' ' u'W' u'+' u' ']]\n",
      "Move #: 3; Taking action: right\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u' ' u'P' u'-' u' ']\n",
      " [u' ' u'W' u'+' u' ']]\n",
      "Move #: 4; Taking action: left\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u'P' u' ' u'-' u' ']\n",
      " [u' ' u'W' u'+' u' ']]\n",
      "Move #: 5; Taking action: right\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u' ' u'P' u'-' u' ']\n",
      " [u' ' u'W' u'+' u' ']]\n",
      "Move #: 6; Taking action: left\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u'P' u' ' u'-' u' ']\n",
      " [u' ' u'W' u'+' u' ']]\n",
      "Move #: 7; Taking action: right\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u' ' u'P' u'-' u' ']\n",
      " [u' ' u'W' u'+' u' ']]\n",
      "Move #: 8; Taking action: left\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u'P' u' ' u'-' u' ']\n",
      " [u' ' u'W' u'+' u' ']]\n",
      "Move #: 9; Taking action: right\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u' ' u'P' u'-' u' ']\n",
      " [u' ' u'W' u'+' u' ']]\n",
      "Move #: 10; Taking action: left\n",
      "[[u' ' u' ' u' ' u' ']\n",
      " [u' ' u' ' u' ' u' ']\n",
      " [u'P' u' ' u'-' u' ']\n",
      " [u' ' u'W' u'+' u' ']]\n",
      "Game lost; too many moves.\n"
     ]
    }
   ],
   "source": [
    "def initGridEvil():\n",
    "    global move_counter\n",
    "    move_counter = 0\n",
    "    state = np.zeros((4,4,4))\n",
    "    #place player\n",
    "    state[2,1] = np.array([0,0,0,1])\n",
    "    #place wall\n",
    "    state[3,1] = np.array([0,0,1,0])\n",
    "    #place pit\n",
    "    state[2,2] = np.array([0,1,0,0])\n",
    "    #place goal\n",
    "    state[3,2] = np.array([1,0,0,0])\n",
    "    return state\n",
    "\n",
    "grid_evil = initGridEvil()\n",
    "#print(dispGrid(grid_evil))\n",
    "testAlgo(grid_evil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board State:\n",
      "[[u' ' u'P' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Policy\n",
      "[[u'>' u'>' u'>' u'v']\n",
      " [u'v' u'>' u'>' u'^']\n",
      " [u'>' u'^' u'<' u'>']\n",
      " [u'v' u'<' u'v' u'^']]\n",
      "Initial State:\n",
      "[[u' ' u'P' u' ' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 0; Taking action: right\n",
      "[[u' ' u' ' u'P' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 1; Taking action: up\n",
      "[[u' ' u' ' u'P' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 2; Taking action: up\n",
      "[[u' ' u' ' u'P' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 3; Taking action: up\n",
      "[[u' ' u' ' u'P' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 4; Taking action: up\n",
      "[[u' ' u' ' u'P' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 5; Taking action: up\n",
      "[[u' ' u' ' u'P' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 6; Taking action: up\n",
      "[[u' ' u' ' u'P' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 7; Taking action: up\n",
      "[[u' ' u' ' u'P' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 8; Taking action: up\n",
      "[[u' ' u' ' u'P' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 9; Taking action: up\n",
      "[[u' ' u' ' u'P' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Move #: 10; Taking action: up\n",
      "[[u' ' u' ' u'P' u' ']\n",
      " [u' ' u'-' u' ' u' ']\n",
      " [u' ' u' ' u'W' u' ']\n",
      " [u' ' u' ' u' ' u'+']]\n",
      "Game lost; too many moves.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEZCAYAAAB2AoVaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0f0809290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "easy_state = initGrid()\n",
    "print(\"Board State:\")\n",
    "print(dispGrid(easy_state))\n",
    "plot_value(easy_state)\n",
    "print(\"Policy\")\n",
    "print(show_policy(hard_state))\n",
    "testAlgo(easy_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
