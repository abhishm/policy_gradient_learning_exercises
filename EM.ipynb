{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### E-M Coin Toss Example as given in the EM tutorial paper by Do and Batzoglou* #### \n",
    "\n",
    "def get_mn_log_likelihood(obs,probs):\n",
    "    \"\"\" Return the (log)likelihood of obs, given the probs\"\"\"\n",
    "    # Multinomial Distribution Log PMF\n",
    "    # ln (pdf)      =             multinomial coeff            *   product of probabilities\n",
    "    # ln[f(x|n, p)] = [ln(n!) - (ln(x1!)+ln(x2!)+...+ln(xk!))] + [x1*ln(p1)+x2*ln(p2)+...+xk*ln(pk)]     \n",
    "\n",
    "    multinomial_coeff_denom= 0\n",
    "    prod_probs = 0\n",
    "    for x in range(0,len(obs)): # loop through state counts in each observation\n",
    "        multinomial_coeff_denom = multinomial_coeff_denom + math.log(math.factorial(obs[x]))\n",
    "        prod_probs = prod_probs + obs[x]*math.log(probs[x])\n",
    "\n",
    "    multinomial_coeff = math.log(math.factorial(sum(obs))) -  multinomial_coeff_denom\n",
    "    likelihood = multinomial_coeff + prod_probs\n",
    "    return likelihood\n",
    "\n",
    "# 1st:  Coin B, {HTTTHHTHTH}, 5H,5T\n",
    "# 2nd:  Coin A, {HHHHTHHHHH}, 9H,1T\n",
    "# 3rd:  Coin A, {HTHHHHHTHH}, 8H,2T\n",
    "# 4th:  Coin B, {HTHTTTHHTT}, 4H,6T\n",
    "# 5th:  Coin A, {THHHTHHHTH}, 7H,3T\n",
    "# so, from MLE: pA(heads) = 0.80 and pB(heads)=0.45\n",
    "\n",
    "# represent the experiments\n",
    "head_counts = np.array([5,9,8,4,7])\n",
    "tail_counts = 10-head_counts\n",
    "experiments = zip(head_counts,tail_counts)\n",
    "\n",
    "# initialise the pA(heads) and pB(heads)\n",
    "pA_heads = np.zeros(100); pA_heads[0] = 0.6\n",
    "pB_heads = np.zeros(100); pB_heads[0] = 0.1\n",
    "\n",
    "# E-M begins!\n",
    "delta = 0.001  \n",
    "j = 0 # iteration counter\n",
    "improvement = float('inf')\n",
    "while (improvement>delta):\n",
    "    expectation_A = np.zeros((5,2), dtype=float) \n",
    "    expectation_B = np.zeros((5,2), dtype=float)\n",
    "    for i in range(0,len(experiments)):\n",
    "        e = experiments[i] # i'th experiment\n",
    "        ll_A = get_mn_log_likelihood(e,np.array([pA_heads[j],1-pA_heads[j]])) # loglikelihood of e given coin A\n",
    "        ll_B = get_mn_log_likelihood(e,np.array([pB_heads[j],1-pB_heads[j]])) # loglikelihood of e given coin B\n",
    "\n",
    "        weightA = math.exp(ll_A) / ( math.exp(ll_A) + math.exp(ll_B) ) \n",
    "        # corresponding weight of A proportional to likelihood of A \n",
    "        weightB = math.exp(ll_B) / ( math.exp(ll_A) + math.exp(ll_B) )\n",
    "        # corresponding weight of B proportional to likelihood of B                            \n",
    "\n",
    "        expectation_A[i] = np.dot(weightA, e) \n",
    "        expectation_B[i] = np.dot(weightB, e)\n",
    "\n",
    "    pA_heads[j+1] = sum(expectation_A)[0] / sum(sum(expectation_A)); \n",
    "    pB_heads[j+1] = sum(expectation_B)[0] / sum(sum(expectation_B)); \n",
    "\n",
    "    improvement = max( abs(np.array([pA_heads[j+1],pB_heads[j+1]]) - np.array([pA_heads[j],pB_heads[j]]) ))\n",
    "    j = j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(1234)\n",
    "\n",
    "np.set_printoptions(formatter={'all':lambda x: '%.3f' % x})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from numpy.core.umath_tests import matrix_multiply as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.stats import bernoulli, binom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neg_loglik(thetas, n, xs, zs):\n",
    "    return -np.sum([binom(n, thetas[z]).logpmf(x) for (x, z) in zip(xs, zs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 10\n",
    "theta_A = 0.8\n",
    "theta_B = 0.3\n",
    "theta_0 = [theta_A, theta_B]\n",
    "\n",
    "coin_A = bernoulli(theta_A)\n",
    "coin_B = bernoulli(theta_B)\n",
    "\n",
    "xs = map(sum, [coin_A.rvs(m), coin_A.rvs(m), coin_B.rvs(m), coin_A.rvs(m), coin_B.rvs(m)])\n",
    "zs = [0, 0, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.000, 9.000, 2.000, 6.000, 0.000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.array(xs)\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.73333333333333328, 0.10000000000000001)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_A = np.sum(xs[[0,1,3]])/(3.0*m)\n",
    "ml_B = np.sum(xs[[2,4]])/(2.0*m)\n",
    "ml_A, ml_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 7.6552677541393193\n",
       "     jac: array([-0.000, -0.000])\n",
       " message: 'Converged (|f_n-f_(n-1)| ~= 0)'\n",
       "    nfev: 17\n",
       "     nit: 6\n",
       "  status: 1\n",
       " success: True\n",
       "       x: array([0.733, 0.100])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnds = [(0,1), (0,1)]\n",
    "minimize(neg_loglik, [0.5, 0.5], args=(m, xs, zs),\n",
    "         bounds=bnds, method='tnc', options={'maxiter': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "theta_A = 0.71, theta_B = 0.58, ll = -32.69\n",
      "Iteration: 2\n",
      "theta_A = 0.75, theta_B = 0.57, ll = -31.26\n",
      "Iteration: 3\n",
      "theta_A = 0.77, theta_B = 0.55, ll = -30.76\n",
      "Iteration: 4\n",
      "theta_A = 0.78, theta_B = 0.53, ll = -30.33\n",
      "Iteration: 5\n",
      "theta_A = 0.79, theta_B = 0.53, ll = -30.07\n",
      "Iteration: 6\n",
      "theta_A = 0.79, theta_B = 0.52, ll = -29.95\n",
      "Iteration: 7\n",
      "theta_A = 0.80, theta_B = 0.52, ll = -29.90\n",
      "Iteration: 8\n",
      "theta_A = 0.80, theta_B = 0.52, ll = -29.88\n",
      "Iteration: 9\n",
      "theta_A = 0.80, theta_B = 0.52, ll = -29.87\n"
     ]
    }
   ],
   "source": [
    "xs = np.array([(5,5), (9,1), (8,2), (4,6), (7,3)])\n",
    "thetas = np.array([[0.6, 0.4], [0.5, 0.5]])\n",
    "\n",
    "tol = 0.01\n",
    "max_iter = 100\n",
    "\n",
    "ll_old = 0\n",
    "for i in range(max_iter):\n",
    "    ws_A = []\n",
    "    ws_B = []\n",
    "\n",
    "    vs_A = []\n",
    "    vs_B = []\n",
    "\n",
    "    ll_new = 0\n",
    "\n",
    "    # E-step: calculate probability distributions over possible completions\n",
    "    for x in xs:\n",
    "\n",
    "        # multinomial (binomial) log likelihood\n",
    "        ll_A = np.sum([x*np.log(thetas[0])])\n",
    "        ll_B = np.sum([x*np.log(thetas[1])])\n",
    "\n",
    "        # [EQN 1]\n",
    "        denom = np.exp(ll_A) + np.exp(ll_B)\n",
    "        w_A = np.exp(ll_A)/denom\n",
    "        w_B = np.exp(ll_B)/denom\n",
    "\n",
    "        ws_A.append(w_A)\n",
    "        ws_B.append(w_B)\n",
    "\n",
    "        # used for calculating theta\n",
    "        vs_A.append(np.dot(w_A, x))\n",
    "        vs_B.append(np.dot(w_B, x))\n",
    "\n",
    "        # update complete log likelihood\n",
    "        ll_new += w_A * ll_A + w_B * ll_B\n",
    "\n",
    "    # M-step: update values for parameters given current distribution\n",
    "    # [EQN 2]\n",
    "    thetas[0] = np.sum(vs_A, 0)/np.sum(vs_A)\n",
    "    thetas[1] = np.sum(vs_B, 0)/np.sum(vs_B)\n",
    "    # print distribution of z for each x and current parameter estimate\n",
    "\n",
    "    print \"Iteration: %d\" % (i+1)\n",
    "    print \"theta_A = %.2f, theta_B = %.2f, ll = %.2f\" % (thetas[0,0], thetas[1,0], ll_new)\n",
    "\n",
    "    if np.abs(ll_new - ll_old) < tol:\n",
    "        break\n",
    "    ll_old = ll_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "theta_A = 0.71, theta_B = 0.58, ll = -32.69\n",
      "Iteration: 2\n",
      "theta_A = 0.75, theta_B = 0.57, ll = -31.26\n",
      "Iteration: 3\n",
      "theta_A = 0.77, theta_B = 0.55, ll = -30.76\n",
      "Iteration: 4\n",
      "theta_A = 0.78, theta_B = 0.53, ll = -30.33\n",
      "Iteration: 5\n",
      "theta_A = 0.79, theta_B = 0.53, ll = -30.07\n",
      "Iteration: 6\n",
      "theta_A = 0.79, theta_B = 0.52, ll = -29.95\n",
      "Iteration: 7\n",
      "theta_A = 0.80, theta_B = 0.52, ll = -29.90\n",
      "Iteration: 8\n",
      "theta_A = 0.80, theta_B = 0.52, ll = -29.88\n",
      "Iteration: 9\n",
      "theta_A = 0.80, theta_B = 0.52, ll = -29.87\n"
     ]
    }
   ],
   "source": [
    "xs = np.array([(5,5), (9,1), (8,2), (4,6), (7,3)])\n",
    "thetas = np.array([[0.6, 0.4], [0.5, 0.5]])\n",
    "\n",
    "tol = 0.01\n",
    "max_iter = 100\n",
    "\n",
    "ll_old = -np.infty\n",
    "for i in range(max_iter):\n",
    "    ll_A = np.sum(xs * np.log(thetas[0]), axis=1)\n",
    "    ll_B = np.sum(xs * np.log(thetas[1]), axis=1)\n",
    "    denom = np.exp(ll_A) + np.exp(ll_B)\n",
    "    w_A = np.exp(ll_A)/denom\n",
    "    w_B = np.exp(ll_B)/denom\n",
    "\n",
    "    vs_A = w_A[:, None] * xs\n",
    "    vs_B = w_B[:, None] * xs\n",
    "\n",
    "    thetas[0] = np.sum(vs_A, 0)/np.sum(vs_A)\n",
    "    thetas[1] = np.sum(vs_B, 0)/np.sum(vs_B)\n",
    "\n",
    "    ll_new = w_A.dot(ll_A) + w_B.dot(ll_B)\n",
    "\n",
    "    print \"Iteration: %d\" % (i+1)\n",
    "    print \"theta_A = %.2f, theta_B = %.2f, ll = %.2f\" % (thetas[0,0], thetas[1,0], ll_new)\n",
    "\n",
    "    if np.abs(ll_new - ll_old) < tol:\n",
    "        break\n",
    "    ll_old = ll_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "theta_A = 0.71, theta_B = 0.58, ll = -29.63\n",
      "Iteration: 2\n",
      "theta_A = 0.75, theta_B = 0.57, ll = -28.39\n",
      "Iteration: 3\n",
      "theta_A = 0.77, theta_B = 0.55, ll = -28.26\n",
      "Iteration: 4\n",
      "theta_A = 0.78, theta_B = 0.53, ll = -28.16\n",
      "Iteration: 5\n",
      "theta_A = 0.79, theta_B = 0.53, ll = -28.12\n",
      "Iteration: 6\n",
      "theta_A = 0.79, theta_B = 0.52, ll = -28.11\n",
      "Iteration: 7\n",
      "theta_A = 0.80, theta_B = 0.52, ll = -28.10\n"
     ]
    }
   ],
   "source": [
    "xs = np.array([(5,5), (9,1), (8,2), (4,6), (7,3)])\n",
    "thetas = np.array([[0.6, 0.4], [0.5, 0.5]])\n",
    "\n",
    "tol = 0.01\n",
    "max_iter = 100\n",
    "\n",
    "ll_old = -np.infty\n",
    "for i in range(max_iter):\n",
    "    ll_A = np.sum(xs * np.log(thetas[0]), axis=1)\n",
    "    ll_B = np.sum(xs * np.log(thetas[1]), axis=1)\n",
    "    denom = np.exp(ll_A) + np.exp(ll_B)\n",
    "    w_A = np.exp(ll_A)/denom\n",
    "    w_B = np.exp(ll_B)/denom\n",
    "\n",
    "    vs_A = w_A[:, None] * xs\n",
    "    vs_B = w_B[:, None] * xs\n",
    "\n",
    "    thetas[0] = np.sum(vs_A, 0)/np.sum(vs_A)\n",
    "    thetas[1] = np.sum(vs_B, 0)/np.sum(vs_B)\n",
    "\n",
    "    ll_new = w_A.dot(ll_A) + w_B.dot(ll_B) - w_A.dot(np.log(w_A)) - w_B.dot(np.log(w_B))\n",
    "\n",
    "    print \"Iteration: %d\" % (i+1)\n",
    "    print \"theta_A = %.2f, theta_B = %.2f, ll = %.2f\" % (thetas[0,0], thetas[1,0], ll_new)\n",
    "\n",
    "    if np.abs(ll_new - ll_old) < tol:\n",
    "        break\n",
    "    ll_old = ll_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def em(xs, thetas, max_iter=100, tol=1e-6):\n",
    "    \"\"\"Expectation-maximization for coin sample problem.\"\"\"\n",
    "\n",
    "    ll_old = -np.infty\n",
    "    for i in range(max_iter):\n",
    "        ll = np.array([np.sum(xs * np.log(theta), axis=1) for theta in thetas])\n",
    "        lik = np.exp(ll)\n",
    "        ws = lik/lik.sum(0)\n",
    "        vs = np.array([w[:, None] * xs for w in ws])\n",
    "        thetas = np.array([v.sum(0)/v.sum() for v in vs])\n",
    "        ll_new = np.sum([w*l for w, l in zip(ws, ll)])\n",
    "        if np.abs(ll_new - ll_old) < tol:\n",
    "            break\n",
    "        ll_old = ll_new\n",
    "    return i, thetas, ll_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[0.797 0.203]\n",
      "[0.520 0.480]\n",
      "-29.868676155\n"
     ]
    }
   ],
   "source": [
    "xs = np.array([(5,5), (9,1), (8,2), (4,6), (7,3)])\n",
    "thetas = np.array([[0.6, 0.4], [0.5, 0.5]])\n",
    "\n",
    "i, thetas, ll = em(xs, thetas)\n",
    "print i\n",
    "for theta in thetas:\n",
    "    print theta\n",
    "print ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "n = 100\n",
    "p0 = 0.8\n",
    "p1 = 0.35\n",
    "xs = np.concatenate([np.random.binomial(n, p0, n/2), np.random.binomial(n, p1, n/2)])\n",
    "xs = np.column_stack([xs, n-xs])\n",
    "np.random.shuffle(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[0.798 0.202]\n",
      "[0.352 0.648]\n",
      "-5756.59565198\n"
     ]
    }
   ],
   "source": [
    "results = [em(xs, np.random.random((2,2))) for i in range(10)]\n",
    "i, thetas, ll =  sorted(results, key=lambda x: x[-1])[-1]\n",
    "print i\n",
    "for theta in thetas:\n",
    "    print theta\n",
    "print ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
